[project]
name = "nano-vllm-export"
version = "0.1.0"
description = "Export Hugging Face Llama models to binary format for nano-vllm"
readme = "README.md"
requires-python = ">=3.8"
dependencies = [
    "torch>=2.0.0",
    "transformers>=4.35.0",
    "numpy>=1.24.0",
    "huggingface-hub>=0.19.0",
]

# No build system needed - these are just scripts
[tool.uv]
dev-dependencies = []

